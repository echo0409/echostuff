---
title: 机器学习二分类模型常见评价指标
date: 2019-07-17 14:37:00 +0800
categories: [学习总结, ML]
tags: [机器学习]
---
机器学习中的模型大多为分类模型，通过分析特征来给样本进行分类。评价一个分类器的优劣常有以下指标。
***
**<h3>混淆矩阵</h3>**

混淆矩阵是监督学习中的一种可视化工具，主要用于比较分类结果和实例的真实信息。矩阵中的每一行代表实例的预测类别，每一列代表实例的真实类别。接下来的许多指标值的计算都基于混淆矩阵完成。  

|  | actual positive | actual negative|
| ------ | ------ | ------ |
| **predictive positive**| TP(Ture Positive) | FP(False Positive) |
| **predictive negative**| FN(False Negative) | TN(Ture Negative) |

***

**<h3>精确率与召回率</h3>**

**精确率(Precision)=TP/(TP+FP)**
**召回率(Recall)=TP/(TP+FN)**

**precision**是相对模型预测而言。假设模型一共预测了100个正例，而其中80个是对的正例，那么precision就是80%。也可以把**precision**也理解为，当模型作出一个新的预测时，它的置信区间是多少，或者它做的这个预测是对的的可能性是多少。**recall**是相对真实的答案而言。假设测试集里面有100个正例，如果模型预测到了40个正例，**recall**就是40%。 

理论上来说，两者的值越高分类器的性能越好，然而事实上这两者在某些情况下是矛盾的，精确率高时，召回率低；精确率低时，召回率高；关于这个性质通过观察PR曲线不难观察出来。比如在搜索网页时，如果只返回最相关的一个网页，那精确率就是100%，而召回率就很低；如果返回全部网页，那召回率为100%，精确率就很低。因此在不同场合需要根据实际需求判断哪个指标跟重要。  

***

**<h3>准确率与F函数</h3>**

**准确率(accuracy)=(TP+TN)/(TP+FP+TN+FN)**  
**F1=2*precision*recall/(preicion+recall)**

准确率反映了模型正确分类的能力。既包含正例也包含负例。
F1值为精确率和召回率的调和平均值，能反映两者的信息。


**<h3>特异性和灵敏度</h3>**

**特异性(specificity)=TN/(FP+TN)**
**灵敏度(sensitivity)=TP/(TP+FN)**

灵敏度是指实际为正例的样本中，判断为正例的比例（例如真正有生病的人中，被医院判断为有生病者的比例）。反映了模型对正例的判断能力。
特异度是指实际为负例的样本中，判断为负例的比例（例如真正未生病的人中，被医院判断为未生病者的比例）。反映了模型对负例的判断能力。

***

**<h3>ROC曲线</h3>**

在众多的机器学习模型中，很多模型输出的是预测概率，而使用精确率、召回率这类指标进行模型评估时，还需要对预测概率设分类阈值，比如预测概率大于阈值为正例，反之为负例。这使得模型多了一个超参数，并且这超参数会影响模型的泛化能力。

接受者操作特征(Receiver Operating Characteristic, ROC)曲线不需要设定这样的阈值，ROC曲线纵坐标是真正率，横坐标是假正率，如下图，去对应的计算公式为：

**真正率(True Positive Rate)=TP/(TP+FN)**
**假正率(False Positive Rate)=FP/(FP+TN)**

真正率即为召回率，也称灵敏度(**sensitivity**)。反映了模型对正例的分类能力。
**1-False Positive Rate=specificity**，特异性反映了模型对负例的分类能力。  

ROC曲线下的面积即为AUC值，AUC的计算方法同时考虑了学习器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器做出合理的评价。AUC对样本类别是否均衡并不敏感，这也是不均衡样本通常用AUC评价学习器性能的一个原因。  

AUC是指随机给定一个正样本和一个负样本，分类器输出该正样本为正的那个概率值比分类器输出该负样本为正的那个概率值要大的可能性。

<center>
<img src='https://pic2.zhimg.com/80/v2-2faecc24c786e8d52bbb2525a433ead5_hd.jpg' style='zoom:60%'></center>  

***

**<h3>PR曲线</h3>**

以召回率R为横轴、以精确率P为纵轴，能够画出P-R曲线。
<center>
<img src='https://pic1.zhimg.com/80/v2-fa55ae6a09aefc608880ccc3f4ce2140_hd.jpg' style='zoom:60%'></center>  
从上图不难发现，precision与Recall的折中(trade off)，曲线越靠近右上角性能越好，曲线下的面积叫AP分数，能在一定程度上反应模型的精确率和召回率都很高的比例。但这个值不方便计算。


***
**参考：**
1. https://en.wikipedia.org/wiki/Confusion_matrix
2. https://zhuanlan.zhihu.com/p/43405406