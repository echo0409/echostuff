---
title: 共享集群使用总结
date: 2020-09-26 15:18:57 +0800
categories: [踩坑总结, 服务器配置]
tags: [tips]
---
最近刚开始用学校的共享集群，踩了不少坑，因此做个总结以供参考～
## 简要介绍
一个计算集群是由一组计算性能强劲的计算机通过高速网络连接后组成。集群中某单台计算机被称为节点（node）。高性能计算集群一般由登录节点、计算节点和存储节点组成。  
用户需要先连接到登录节点，登录节点是连接整个集群的入口。用户通过登录节点来进一步访问计算节点和存储节点。  
计算节点，是提供计算服务的计算机节点，可以是CPU节点或GPU节点。通常情况下，一个用户作业任务需要一台或多台计算节点来支持其计算服务。将某个计算作业任务分配到不同计算节点上进行计算的工具被称为作业调度系统。  
计算作业一般需要读写文件，我们采用了共享存储系统，将存储节点的磁盘空间映射到所有计算节点上。共享存储的可用磁盘容量非常大，这样一个大容量的磁盘空间被映射到用户的目录上。映射后，用户可以像操作本地的文件一样操作远程的存储节点上的文件。  
了解到以上这些之后，我们就能够明白如何利用集群来提交作业：连接登录节点->访问计算节点/存储节点。
## 如何连接登录节点？
学校的共享集群很贴心的提供了图形化界面，在校内或挂学校VPN之后，就可以通过云超算页面进入。但是我更习惯通过ssh访问远程服务器。不过我现在不在校内，借了师兄的学校VPN账号才可以登录。  
```C
ssh u'学号'@ip -p 端口
```

## 如何访问计算节点？
学校的集群项目采用了Slurm作业调度系统，在需要使用计算节点时，有提交脚本和交互式访问两种方式可供选择。Slurm系统有一些常用命令：
```c
sinfo
// 得到当前集群的队列信息，查看可供使用的计算节点
sinfo -p cpu
// 查看指定分区节点空闲状态，如cpu,gpu,fat
squeue -u `whoami`
// 查看当前队列中本用户的作业及执行情况
scancel 43
//取消id为43的作业
scancel -u `whoami`
// 取消本用户的所有作业
sbatch run.sh
//提交脚本
```
  

  
### 提交脚本
编写脚本，如run.sh，将脚本和可执行程序放在同一目录下，然后通过命令：sbatch run.sh，即可提交。  

```python
#!/bin/bash

### 给你这个作业起个名字，方便识别不同的作业
#SBATCH --job-name=example

### 指定该作业需要多少个节点
#SBATCH --nodes=1

### 指定该作业需要多少个CPU
#SBATCH --ntasks=4

### 指定该作业在哪个队列上执行
### 目前可用的队列有 cpu/fat/titan/tesla
#SBATCH --partition=cpu

### 本例使用Anaconda中的Python，先将Python添加到环境变量配置好环境变量
export PATH=/opt/app/anaconda3/bin:$PATH
### 激活一个 Anaconda 环境 tf22
source activate tf22

### 执行你的作业
python test.py
```

### 交互式访问
提交脚本的方式在程序仍需验证可行性时相当不方便，一般推荐先使用交互式访问确保程序正确执行后，再使用提交脚本的方法丢到云端进行计算。交互式访问也比较简单，只需要通过命令申请node即可。
```c
salloc --nodes=1 --ntasks=8 --partition=cpu --time=00:10:00
// 在cpu队列申请1个节点，每个节点8个核心，时间为10分钟
// --partition=cpu/tesla/titan/fat
``` 
申请后，系统会分配node,然后通过ssh即可登录到指定的计算节点，如ssh tesla1/titan2。

## 存储数据
通过scp存储即可，地址和端口为登录节点。

## 需要注意的点
程序中的路径要采用绝对地址！非常重要！
```c
/home/u'学号'/...
```


***
参考：https://cc.ruc.edu.cn/help
